Confidence-Weighted Multi-Agent RAG (CW-MARAG)

A contradiction-aware, confidence-driven Retrieval-Augmented Generation architecture for grounded question answering from documents.

ğŸ“Œ Overview

Confidence-Weighted Multi-Agent Retrieval-Augmented Generation (CW-MARAG) is a novel RAG architecture designed to reduce hallucinations and handle contradictory evidence in document-based question answering systems.

Unlike conventional RAG pipelines that rely on a single retriever or naive score aggregation, CW-MARAG employs multiple specialized retrieval agents whose outputs are evaluated, weighted, and arbitrated using confidence-aware fusion before generation.

The system is particularly suited for:

Academic & legal documents

Policy PDFs

Technical manuals

Any domain where contradictions and uncertainty matter

ğŸ§  Core Idea

Not all retrieved evidence deserves equal trust.

CW-MARAG explicitly models this by:

Using multiple retrieval perspectives

Assigning confidence scores to each evidence chunk

Detecting contradictions

Allowing the generator to abstain when evidence is insufficient or conflicting

ğŸ—ï¸ System Architecture
ğŸ”¹ Multi-Agent Retrieval Layer

Independent agents retrieve evidence using different strategies:

Semantic Retriever â€“ dense embeddings (semantic similarity)

Keyword Retriever â€“ lexical / term-based matching

Temporal Retriever â€“ time-aware relevance

Contradiction Retriever â€“ detects conflicting statements

Each agent operates independently, improving coverage and robustness.

ğŸ”¹ Confidence Scoring & Arbitration

Each retrieved chunk is evaluated on:

Retrieval strength

Agreement with other agents

Contradiction signals

Chunks are labeled as:

Trusted evidence

Contradictory evidence

Low-confidence evidence

A fusion module arbitrates which evidence is safe to use.

ğŸ”¹ Controlled Generation

The LLM is guided with:

Only trusted evidence

Explicit instructions to abstain when confidence is low

This prevents:

Hallucinated answers

Overconfident responses from weak evidence

ğŸ”¬ Key Features

âœ… Multi-agent retrieval (semantic, keyword, contradiction-aware)

âœ… Confidence-weighted evidence fusion

âœ… Explicit contradiction handling

âœ… Abstention on insufficient evidence

âœ… Local LLM support (Ollama-compatible)

âœ… Streamlit-based interactive interface

ğŸ“‚ Project Structure
confidence-weighted-rag/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/                # Upload & query endpoints
â”‚   â”œâ”€â”€ retrievers/         # Multi-agent retrievers
â”‚   â”œâ”€â”€ arbitration/        # Confidence scoring & fusion
â”‚   â”œâ”€â”€ llm/                # LLM generator interface
â”‚   â””â”€â”€ main.py             # Application entry
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ index/              # Vector indices
â”‚   â””â”€â”€ uploads/            # Uploaded documents
â”‚
â”œâ”€â”€ streamlit_app.py        # UI
â”œâ”€â”€ test_*.py               # Evaluation tests
â””â”€â”€ README.md

âš™ï¸ Tech Stack

Language: Python 3.9+

LLM: Ollama (CodeLLaMA / compatible models)

Retrieval: FAISS, custom retrievers

Embeddings: Sentence-level embeddings

Frontend: Streamlit

Backend: Modular Python architecture

ğŸš€ How It Works (High Level)

User uploads PDFs

Documents are indexed

Query triggers parallel retrieval agents

Evidence is scored & arbitrated

LLM generates:

an answer or

an abstention if confidence is low

ğŸ“Š Example Behavior
Scenario	System Response
Strong agreement across agents	Confident answer
Conflicting evidence	Abstains with explanation
Insufficient evidence	â€œInsufficient evidence to answerâ€
ğŸ§ª Evaluation Philosophy

CW-MARAG prioritizes:

Correct abstention over wrong answers

Faithfulness over fluency

Explainability over blind confidence

This aligns with emerging best practices in trustworthy AI and responsible RAG systems.

ğŸ“š Research & Novelty
What makes CW-MARAG different?

Confidence-weighted arbitration (not simple ranking)

Explicit contradiction modeling

Multi-agent evidence disagreement handling

Generator-level abstention logic

These aspects make CW-MARAG suitable for:

Research publication

Patent filing

High-stakes QA systems

ğŸ”’ License

MIT License â€” open for research and extension.

ğŸ‘¤ Author

Alex Rohith
AI & ML Engineer
Focus areas: RAG systems, LLM reliability, trustworthy AI
